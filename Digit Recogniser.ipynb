{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae1794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "467ac5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "link='C:/Users/NavneethBhat/Desktop/Code/Implementations/data/train.csv/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af740b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self,link):\n",
    "        dataset=pd.read_csv(link,dtype=np.float32)\n",
    "        y=dataset['label'].values\n",
    "        x=dataset.drop('label',axis=1).values\n",
    "        self.x=torch.from_numpy(x)\n",
    "        self.y=torch.from_numpy(y)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c1841bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DigitDataset(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8215d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f3ffea850>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels,_=data[4]\n",
    "pixels=pixels.view((28,28))\n",
    "plt.imshow(pixels,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "456a9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cb29a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=784\n",
    "hidden_size=100\n",
    "num_classes=10\n",
    "num_epochs=30\n",
    "batch_size=100\n",
    "learning_rate=2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b96dd",
   "metadata": {},
   "source": [
    "dataset define->hyperparameters->dataload->model->optimizer and loss function->train->test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cd7406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93f1efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        #\n",
    "        self.c1=nn.Conv2d\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2ae3571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (l3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d4bb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d880e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        labels=labels.type(torch.LongTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        preds=model(images)\n",
    "        loss=criterion(preds,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64df4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1=DataLoader(dataset=data,shuffle=True)\n",
    "a,b=next(iter(train_loader1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "147fa6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7ae070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.8936, device='cuda:0')\n",
      "tensor([9.])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    a=a.to(device)\n",
    "    op=model(a)\n",
    "    pred=torch.max(op.data)\n",
    "    print(pred)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb17fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'C:/Users/NavneethBhat/Desktop/vals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62e1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
